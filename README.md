# ðŸ§  Fake News Detection using Transformer Models  
### *A Comparative Study of Human vs AI Judgment*

---

## ðŸ“„ Project Overview
This project investigates how **Artificial Intelligence** compares to **human intuition** in detecting fake news.  
A transformer-based NLP model (**DistilBERT**) was fine-tuned on English news articles to classify them as *real* or *fake*, and its performance was evaluated against a human participantâ€™s manual judgments.

---

## ðŸŽ¯ Objectives
- Build a reproducible end-to-end fake news detection pipeline.  
- Clean and normalize the Kaggle *Fake/Real News* dataset.  
- Establish a **TF-IDF + Logistic Regression** baseline.  
- Fine-tune **DistilBERT** and compare its accuracy to human evaluation.  
- Analyze misclassification patterns and discuss implications for AI trust and interpretability.

---

## ðŸ“š Verified Literature (2023â€“2025)

1. **Ramzan, A., Ali, R. H., Ali, N., & Khan, A. (2024).** *Enhancing Fake News Detection Using BERT: A Comparative Analysis of Logistic Regression, RFC, LSTM and BERT.* In 2024 International Conference on IT and Industrial Technologies (ICIT). IEEE. DOI: [10.1109/ICIT63607.2024.10859673](https://doi.org/10.1109/ICIT63607.2024.10859673)  
2. **Kitanovski, M., & Mitrevski, P. (2023).** *DistilBERT and RoBERTa Models for Identification of Fake News.* 46th MIPRO ICT and Electronics Convention. IEEE. DOI: [10.23919/MIPRO57284.2023.10159740](https://doi.org/10.23919/MIPRO57284.2023.10159740)  
3. **Saadi, A., Belhadef, H., Guessas, A., & Hafirassou, O. (2025).** *Enhancing Fake News Detection with Transformer Models and Summarization.* *Engineering, Technology & Applied Science Research, 15*(3), 23253â€“23259. DOI: [10.48084/etasr.10678](https://doi.org/10.48084/etasr.10678)

*Dataset citation:* Kaggle. *Fake and Real News Dataset.* Retrieved 2025.

---

## ðŸ“Š Dataset Collection & Preparation

**Source:** Kaggle â€“ *Fake and Real News Dataset*  
**Files used:** `Fake.csv` (23,481 rows), `True.csv` (21,417 rows)  
**Total combined:** 44,898 records  

### Columns
1. `title`  
2. `text`  
3. `subject`  
4. `date`  
5. `label`  
6. `content`  

The `content` column merges **title** and **text** to create richer contextual input for modeling.

Cleaning highlights:
- Removed duplicates
- Filtered very short texts (<50 characters)
- Normalized text (URLs, symbols, whitespace)

---

## âš™ï¸ Model Architecture & Workflow

### 1ï¸âƒ£ Baseline Model
- **TF-IDF + Logistic Regression**
- Metrics (validated from notebooks & figures):  
  | Metric | TF-IDF + Logistic Regression | DistilBERT (Fine-Tuned) |
  |:--|:--:|:--:|
  | Accuracy | **0.9856** | **0.9987** |
  | Precision | **0.9818** | **0.9987** |
  | Recall | **0.9922** | **0.9987** |
  | F1-score | **0.9870** | **0.9987** |
- Total misclassifications: **111** (LogReg) vs **10** (DistilBERT).  
- Confusion matrices and metric bars are available under `figures/`.

### 2ï¸âƒ£ Fine-Tuned Model
- **Model:** DistilBERT Base Uncased (Hugging Face)
- **Optimizer:** AdamW (Hugging Face Trainer)
- **Learning Rate:** 2e-5
- **Epochs:** 2
- **Batch Size:** 8 (train & eval)
- **Warmup Steps:** 100
- **Weight Decay:** 0.01
- **Evaluation Strategy:** Per epoch
- **Save Strategy:** Per epoch
- **Final Accuracy:** **0.9987** (validation set)
- **Metrics Visualization:** `figures/metrics_comparison_bar.png`, `figures/confusion_matrices_comparison.png`, `figures/total_misclassifications.png`

### 3ï¸âƒ£ Explainability
**SHAP (SHapley Additive Explanations)** will be integrated in a future version to interpret token-level importance and explain model decisions.

---

## ðŸ§© Project Structure

```
â”œâ”€â”€ README.md
â”œâ”€â”€ Requirements.txt
â”œâ”€â”€ app.py
â”œâ”€â”€ data
â”‚   â””â”€â”€ processed
â”‚       â””â”€â”€ cleaned_combined.csv
â”œâ”€â”€ datasets
â”‚   â”œâ”€â”€ Fake.csv
â”‚   â””â”€â”€ True.csv
â”œâ”€â”€ figures
â”‚   â”œâ”€â”€ confusion_matrices_comparison.png
â”‚   â”œâ”€â”€ metrics_comparison_bar.png
â”‚   â”œâ”€â”€ model_comparison_metrics.csv
â”‚   â””â”€â”€ total_misclassifications.png
â”œâ”€â”€ notebooks
â”‚   â”œâ”€â”€ 01_data_preparation.ipynb
â”‚   â”œâ”€â”€ 02_baseline_model.ipynb
â”‚   â”œâ”€â”€ 03_distilbert_finetuning.ipynb
â”‚   â””â”€â”€ 04_evaluation_and_results.ipynb
â””â”€â”€ trained_distilbert_fake_news
    â”œâ”€â”€ config.json
    â”œâ”€â”€ model.safetensors
    â””â”€â”€ training_args.bin
```

---

## âš ï¸ Note on Git LFS Files
This repository uses **Git Large File Storage (LFS)** for large model and dataset files.

Tracked via LFS:
- `data/processed/cleaned_combined.csv`
- `datasets/Fake.csv`
- `datasets/True.csv`
- `trained_distilbert_fake_news/model.safetensors`

If cloning the repo, run:
```bash
git lfs install
git lfs pull
```

---

## ðŸ§° Tools & Libraries
| Category | Libraries |
|-----------|------------|
| Core | Pandas, NumPy, scikit-learn |
| NLP | Transformers, Datasets, Tokenizers |
| ML | PyTorch, Accelerate, Safetensors |
| Visualization | Matplotlib |
| Explainability | SHAP (planned) |
| Dashboard | Streamlit |
| Dev Tools | JupyterLab, Git, Git LFS |

---

## ðŸš€ Quick Setup & Run

### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/erenbg1/B198_project.git
cd B198_project
```

### 2ï¸âƒ£ Install dependencies
```bash
pip install -r Requirements.txt
```

### 3ï¸âƒ£ Pull LFS files (if needed)
```bash
git lfs install
git lfs pull
```

### 4ï¸âƒ£ Run the Streamlit dashboard
```bash
streamlit run app.py
```
The dashboard allows users to test news articles in real time and view prediction confidence.

---

## ðŸ§  Results Summary
The TF-IDF baseline achieved **98.56% accuracy**, while the fine-tuned **DistilBERT reached 99.87%** on the validation set.  
Removing very short texts (<50 characters) improved overall consistency and model focus.

---

## ðŸ”® Future Work
- Add SHAP explainability  
- Add multilingual dataset 
- Deploy as online verification tool  

---

## ðŸ‘¤ Author
**Eren Burak GÃ¶kpÄ±nar**  
GISMA University of Applied Sciences  
**Module:** B198 End-to-End Project  

---

## ðŸ License
This project is distributed for educational and research purposes under the MIT License.  
See the full license text in `LICENSE` if provided.
